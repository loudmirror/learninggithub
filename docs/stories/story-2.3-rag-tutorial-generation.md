# Story 2.3: RAG æ•™ç¨‹ç”ŸæˆæœåŠ¡

## ğŸ“‹ Story å…ƒä¿¡æ¯

- **Story ID**: STORY-2.3
- **Epic**: MVP v0.1
- **æ‰€å±è¿­ä»£**: è¿­ä»£ 2 - çœŸå®æœåŠ¡é›†æˆ
- **çŠ¶æ€**: Draft
- **ä¼˜å…ˆçº§**: High
- **é¢„ä¼°æ—¶é—´**: 3-4 å¤©
- **è´Ÿè´£äºº**: Dev Agent
- **ä¾èµ–**: STORY-2.2 (å†…å®¹å¤„ç†ä¸å‘é‡åŒ–æœåŠ¡)

---

## ğŸ“– User Story

**As a** ç”¨æˆ·
**I want** ç³»ç»Ÿèƒ½å¤ŸåŸºäºå‘é‡æ£€ç´¢ç”Ÿæˆä¸ªæ€§åŒ–çš„å­¦ä¹ æ•™ç¨‹
**So that** æˆ‘å¯ä»¥è·å¾—é’ˆå¯¹ç‰¹å®šä»“åº“çš„ç»“æ„åŒ–ã€æ˜“æ‡‚çš„å­¦ä¹ è·¯å¾„

---

## ğŸ¯ èƒŒæ™¯ä¸ä¸Šä¸‹æ–‡

### é¡¹ç›®ä¸Šä¸‹æ–‡
RAG (Retrieval Augmented Generation) æ˜¯æœ¬é¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ã€‚åœ¨ Story 2.2 å®Œæˆå‘é‡åŒ–åï¼Œæœ¬ Story éœ€è¦ï¼š
1. åŸºäºç”¨æˆ·è¾“å…¥çš„ä»“åº“ URLï¼Œä» ChromaDB æ£€ç´¢ç›¸å…³ä»£ç ç‰‡æ®µ
2. æ„å»ºåŒ…å«ä»£ç ä¸Šä¸‹æ–‡çš„ prompt
3. è°ƒç”¨ OpenAI Chat API ç”Ÿæˆæ•™ç¨‹å†…å®¹
4. è§£æ LLM è¾“å‡ºï¼Œç”Ÿæˆç»“æ„åŒ–çš„æ•™ç¨‹æ•°æ®ï¼ˆmodules, stepsï¼‰
5. ç¡®ä¿ç”Ÿæˆçš„æ•™ç¨‹ç¬¦åˆ UX è§„æ ¼å®šä¹‰çš„æ ¼å¼

### æŠ€æœ¯ä¸Šä¸‹æ–‡
- **LLM æ¨¡å‹**: OpenAI `gpt-4-turbo-preview` (æ¨ç†èƒ½åŠ›å¼ºï¼Œé€‚åˆç”Ÿæˆç»“æ„åŒ–å†…å®¹)
- **æ£€ç´¢ç­–ç•¥**:
  - ç¬¬ä¸€é˜¶æ®µ: æ£€ç´¢ README å’Œå…³é”®é…ç½®æ–‡ä»¶ï¼ˆå¦‚ package.jsonï¼‰
  - ç¬¬äºŒé˜¶æ®µ: åŸºäºç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„åˆæ­¥ç†è§£ï¼Œæ£€ç´¢ç›¸å…³ä»£ç æ–‡ä»¶
- **Prompt Engineering**:
  - System Prompt: å®šä¹‰åŠ©æ‰‹è§’è‰²å’Œè¾“å‡ºæ ¼å¼
  - Few-shot Examples: æä¾›ç¤ºä¾‹æ•™ç¨‹ç»“æ„
  - Chain of Thought: å¼•å¯¼ LLM é€æ­¥ç”Ÿæˆ
- **è¾“å‡ºæ ¼å¼**: JSON (ä¸¥æ ¼éµå¾ª frontend schemas)

### è¿­ä»£ç›®æ ‡
å®ç°ä»ä»“åº“ URL åˆ°å®Œæ•´æ•™ç¨‹çš„ç«¯åˆ°ç«¯ç”Ÿæˆæµç¨‹ï¼Œæ›¿ä»£ Story 1.1 çš„ Mock æ•°æ®ã€‚

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½æ€§éœ€æ±‚

1. **AC-2.3.1**: å‘é‡æ£€ç´¢æœåŠ¡èƒ½å¤Ÿä» ChromaDB æŸ¥è¯¢ç›¸å…³ä»£ç ç‰‡æ®µ
   - æ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
   - è¿”å› Top-K ä¸ªæœ€ç›¸å…³çš„ chunks (K=10-20)
   - æ¯ä¸ªç»“æœåŒ…å«: ä»£ç å†…å®¹ã€æ–‡ä»¶è·¯å¾„ã€å…ƒæ•°æ®
   - è¿‡æ»¤æ‰ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœï¼ˆå¦‚ cosine similarity < 0.7ï¼‰

2. **AC-2.3.2**: Prompt æ„å»ºç­–ç•¥ç¬¦åˆæœ€ä½³å®è·µ
   - System Prompt æ¸…æ™°å®šä¹‰ä»»åŠ¡å’Œè¾“å‡ºæ ¼å¼
   - åŒ…å« Few-shot Examplesï¼ˆè‡³å°‘ 1 ä¸ªå®Œæ•´ç¤ºä¾‹ï¼‰
   - åŠ¨æ€æ³¨å…¥æ£€ç´¢åˆ°çš„ä»£ç ä¸Šä¸‹æ–‡
   - æ§åˆ¶æ€» token æ•° â‰¤ 6000ï¼ˆé¿å…è¶…å‡ºæ¨¡å‹é™åˆ¶ï¼‰

3. **AC-2.3.3**: LLM è°ƒç”¨æ¥å£ç¨³å®šå¯é 
   - ä½¿ç”¨ `gpt-4-turbo-preview` æˆ– `gpt-4`
   - æ”¯æŒ JSON Modeï¼ˆ`response_format: { "type": "json_object" }`ï¼‰
   - æ¸©åº¦è®¾ç½®: 0.3ï¼ˆå¹³è¡¡åˆ›é€ æ€§å’Œç¡®å®šæ€§ï¼‰
   - Max Tokens: 4000
   - å®ç°æŒ‡æ•°é€€é¿é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
   - å¤„ç† Rate Limitã€Timeout ç­‰é”™è¯¯

4. **AC-2.3.4**: ç”Ÿæˆçš„æ•™ç¨‹æ•°æ®ç¬¦åˆå‰ç«¯ Schema
   ```typescript
   interface TutorialData {
     repo: RepoInfo;
     overview: string;
     prerequisites: string[];
     structure: {
       directories: DirectoryItem[];
       files: FileItem[];
     };
     modules: Module[];
     steps: Step[];
   }
   ```
   - æ‰€æœ‰å­—æ®µå¿…é¡»å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
   - `modules` æ•°ç»„é•¿åº¦: 3-8 ä¸ª
   - æ¯ä¸ª `module` åŒ…å« 2-6 ä¸ª `stepIds`
   - `steps` æ•°ç»„ä¸ `stepIds` å¼•ç”¨ä¸€è‡´
   - `overview` é•¿åº¦: 200-500 å­—ç¬¦
   - `prerequisites` æ•°ç»„é•¿åº¦: 2-6 é¡¹

5. **AC-2.3.5**: æ•™ç¨‹è´¨é‡ç¬¦åˆæ ‡å‡†
   - Overview å‡†ç¡®æè¿°ä»“åº“æ ¸å¿ƒåŠŸèƒ½
   - Prerequisites åŒ…å«å¿…è¦çš„æŠ€æœ¯è¦æ±‚ï¼ˆå¦‚ Node.js ç‰ˆæœ¬ï¼‰
   - Modules æŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡ï¼ˆç¯å¢ƒæ­å»º â†’ æ ¸å¿ƒåŠŸèƒ½ â†’ è¿›é˜¶ä¸»é¢˜ï¼‰
   - Steps å…·æœ‰å¯æ‰§è¡Œæ€§ï¼ˆåŒ…å«å…·ä½“å‘½ä»¤æˆ–ä»£ç ç¤ºä¾‹ï¼‰
   - ä»£ç ç¤ºä¾‹ä½¿ç”¨æ­£ç¡®çš„è¯­æ³•é«˜äº®æ ‡è®°ï¼ˆå¦‚ ```pythonã€```typescriptï¼‰

6. **AC-2.3.6**: API ç«¯ç‚¹è®¾è®¡ç¬¦åˆè§„èŒƒ
   ```
   POST /api/tutorial/generate
   Body: { "repo_url": "https://github.com/..." }
   Response: {
     "ok": true,
     "data": {
       "task_id": "...",
       "status": "processing"
     }
   }

   GET /api/tutorial/{task_id}
   Response: {
     "ok": true,
     "data": {
       "status": "completed",
       "tutorial": { /* TutorialData */ }
     }
   }
   ```

7. **AC-2.3.7**: æ”¯æŒç¼“å­˜æœºåˆ¶
   - ç›¸åŒä»“åº“ URL çš„æ•™ç¨‹ç¼“å­˜ 24 å°æ—¶
   - ç¼“å­˜é”®: `tutorial:{owner}:{repo}:{commit_sha}`
   - ä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆMVP é˜¶æ®µï¼‰æˆ– Redisï¼ˆå¯é€‰ï¼‰
   - æä¾›å¼ºåˆ¶åˆ·æ–°é€‰é¡¹: `POST /api/tutorial/generate?force=true`

8. **AC-2.3.8**: é”™è¯¯å¤„ç†å®Œå–„
   - ä»“åº“æœªå‘é‡åŒ–: è¿”å› 404 with æç¤º "Repository not vectorized"
   - LLM è¾“å‡ºæ ¼å¼é”™è¯¯: é‡è¯•æˆ–è¿”å›é»˜è®¤ç»“æ„
   - OpenAI API é”™è¯¯: è®°å½•æ—¥å¿—ï¼Œè¿”å›å‹å¥½é”™è¯¯ä¿¡æ¯
   - è¶…æ—¶å¤„ç†: ä»»åŠ¡è¶…æ—¶æ—¶é—´ 5 åˆ†é’Ÿ

### è´¨é‡éœ€æ±‚

9. **AC-2.3.9**: æ€§èƒ½æ»¡è¶³è¦æ±‚
   - ç”Ÿæˆå•ä¸ªæ•™ç¨‹ â‰¤ 60 ç§’ï¼ˆP95ï¼‰
   - å‘é‡æ£€ç´¢ â‰¤ 2 ç§’
   - LLM è°ƒç”¨ â‰¤ 30 ç§’
   - å¹¶å‘æ”¯æŒ: 5 ä¸ªåŒæ—¶è¿›è¡Œçš„ç”Ÿæˆä»»åŠ¡

10. **AC-2.3.10**: å•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
    - æµ‹è¯•å‘é‡æ£€ç´¢é€»è¾‘ï¼ˆMock ChromaDBï¼‰
    - æµ‹è¯• Prompt æ„å»ºï¼ˆéªŒè¯æ ¼å¼ï¼‰
    - æµ‹è¯• LLM è¾“å‡ºè§£æï¼ˆMock OpenAI APIï¼‰
    - æµ‹è¯•ç¼“å­˜æœºåˆ¶
    - æµ‹è¯•é”™è¯¯å¤„ç†

11. **AC-2.3.11**: ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ
    - éµå¾ª `coding-standards.md` ä¸­çš„ Python è§„èŒƒ
    - ä½¿ç”¨ Type Hints
    - ä½¿ç”¨ Pydantic è¿›è¡Œæ•°æ®éªŒè¯
    - ä½¿ç”¨ structlog è®°å½•ç»“æ„åŒ–æ—¥å¿—

12. **AC-2.3.12**: Prompt å¯ç»´æŠ¤æ€§
    - Prompt æ¨¡æ¿å­˜å‚¨åœ¨ç‹¬ç«‹æ–‡ä»¶ï¼ˆå¦‚ `prompts/tutorial_generation.txt`ï¼‰
    - æ”¯æŒç‰ˆæœ¬æ§åˆ¶å’Œ A/B æµ‹è¯•
    - åŒ…å«æ³¨é‡Šè¯´æ˜æ¯ä¸ªéƒ¨åˆ†çš„ä½œç”¨

---

## ğŸ”§ æŠ€æœ¯å®ç°ä»»åŠ¡

### Task 1: è®¾è®¡æ•°æ®æ¨¡å‹å’Œ Schemas
**é¢„ä¼°**: 30 åˆ†é’Ÿ

åœ¨ `backend/app/schemas/` ä¸­åˆ›å»ºæ•™ç¨‹æ•°æ®æ¨¡å‹ï¼š

```python
# backend/app/schemas/tutorial.py
from typing import List, Literal, Optional
from pydantic import BaseModel, Field

class RepoInfo(BaseModel):
    """ä»“åº“ä¿¡æ¯"""
    owner: str
    name: str
    description: Optional[str] = None
    stars: int = 0
    language: Optional[str] = None
    url: str

class DirectoryItem(BaseModel):
    """ç›®å½•é¡¹"""
    name: str
    description: str

class FileItem(BaseModel):
    """æ–‡ä»¶é¡¹"""
    name: str
    description: str

class DirectoryStructure(BaseModel):
    """ç›®å½•ç»“æ„"""
    directories: List[DirectoryItem] = []
    files: List[FileItem] = []

class Step(BaseModel):
    """å­¦ä¹ æ­¥éª¤"""
    id: str
    title: str
    description: str
    command: Optional[str] = None
    code: Optional[str] = None
    language: Optional[str] = None

class Module(BaseModel):
    """å­¦ä¹ æ¨¡å—"""
    id: str
    title: str
    description: str
    stepIds: List[str] = Field(..., alias="stepIds")

    class Config:
        populate_by_name = True

class TutorialData(BaseModel):
    """å®Œæ•´æ•™ç¨‹æ•°æ®"""
    repo: RepoInfo
    overview: str = Field(..., min_length=200, max_length=1000)
    prerequisites: List[str] = Field(..., min_items=2, max_items=10)
    structure: DirectoryStructure
    modules: List[Module] = Field(..., min_items=3, max_items=8)
    steps: List[Step]

class GenerateTutorialRequest(BaseModel):
    """ç”Ÿæˆæ•™ç¨‹è¯·æ±‚"""
    repo_url: str
    force: bool = False  # å¼ºåˆ¶åˆ·æ–°

class TutorialGenerationStatus(BaseModel):
    """æ•™ç¨‹ç”ŸæˆçŠ¶æ€"""
    task_id: str
    status: Literal["pending", "processing", "completed", "failed"]
    progress: Optional[dict] = None
    error: Optional[str] = None
    tutorial: Optional[TutorialData] = None
```

---

### Task 2: å®ç°å‘é‡æ£€ç´¢æœåŠ¡
**é¢„ä¼°**: 1.5 å°æ—¶

æ‰©å±• `backend/app/services/vector_store.py`:

```python
from typing import List, Dict
import structlog

logger = structlog.get_logger()

class VectorStore:
    # ... ä¹‹å‰çš„ä»£ç  ...

    async def search_similar_chunks(
        self,
        repo_owner: str,
        repo_name: str,
        query: str,
        top_k: int = 20,
        min_similarity: float = 0.7
    ) -> List[Dict]:
        """æ£€ç´¢ç›¸ä¼¼ä»£ç å—"""
        from app.services.embedder import EmbeddingService

        collection = self.get_or_create_collection(repo_owner, repo_name)

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        embedder = EmbeddingService()
        query_embedding = await embedder.generate_embeddings([
            type('Chunk', (), {'content': query})()
        ])

        # æ‰§è¡Œæ£€ç´¢
        results = collection.query(
            query_embeddings=query_embedding,
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )

        # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
        filtered_results = []
        for i, distance in enumerate(results["distances"][0]):
            # ChromaDB ä½¿ç”¨ L2 è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦
            similarity = 1 / (1 + distance)

            if similarity >= min_similarity:
                filtered_results.append({
                    "content": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "similarity": similarity
                })

        logger.info(
            "vector_search_completed",
            repo=f"{repo_owner}/{repo_name}",
            total_results=len(results["documents"][0]),
            filtered_results=len(filtered_results)
        )

        return filtered_results

    async def get_readme_content(
        self,
        repo_owner: str,
        repo_name: str
    ) -> Optional[str]:
        """è·å– README å†…å®¹"""
        collection = self.get_or_create_collection(repo_owner, repo_name)

        # æŸ¥æ‰¾ README æ–‡ä»¶
        results = collection.get(
            where={"file_path": {"$regex": "(?i)readme\\.md"}},
            limit=1
        )

        if results["documents"]:
            return results["documents"][0]

        return None
```

**æµ‹è¯•**: åˆ›å»º `backend/tests/test_vector_store_search.py`

---

### Task 3: åˆ›å»º Prompt æ¨¡æ¿
**é¢„ä¼°**: 2 å°æ—¶

åˆ›å»º `backend/app/prompts/tutorial_generation.txt`:

```text
You are an expert technical writer and software educator. Your task is to analyze a GitHub repository and generate a comprehensive, beginner-friendly tutorial that helps users understand and learn the project.

## Input Context

You will receive:
1. Repository metadata (name, description, language, stars)
2. README content
3. Key configuration files (e.g., package.json, requirements.txt)
4. Relevant code snippets from the repository

## Output Format

You MUST respond with a valid JSON object following this exact structure:

{
  "overview": "A clear, concise overview (200-500 chars) explaining what this project does and its main purpose.",
  "prerequisites": [
    "Prerequisite 1 (e.g., Node.js 18.17 or higher)",
    "Prerequisite 2 (e.g., Basic understanding of React)",
    "..."
  ],
  "structure": {
    "directories": [
      {
        "name": "src/",
        "description": "Main source code directory"
      }
    ],
    "files": [
      {
        "name": "package.json",
        "description": "Project dependencies and scripts"
      }
    ]
  },
  "modules": [
    {
      "id": "module-1",
      "title": "Module Title",
      "description": "Module description",
      "stepIds": ["step-1", "step-2"]
    }
  ],
  "steps": [
    {
      "id": "step-1",
      "title": "Step Title",
      "description": "Detailed step description with explanations",
      "command": "npm install",
      "code": "const example = 'code';",
      "language": "javascript"
    }
  ]
}

## Generation Guidelines

1. **Overview**:
   - Focus on the "what" and "why" of the project
   - Mention key technologies used
   - Highlight main features or use cases

2. **Prerequisites**:
   - Include version requirements (e.g., Node.js 18+)
   - List required knowledge (e.g., "Basic TypeScript knowledge")
   - Mention necessary tools (e.g., Git, Docker)

3. **Structure**:
   - Describe 5-10 most important directories
   - Describe 5-10 most important files
   - Explain the purpose of each item clearly

4. **Modules** (3-8 modules):
   - Module 1: "Environment Setup" (initial setup, installation)
   - Module 2-N: Core features and concepts (organized logically)
   - Last Module: "Next Steps" (advanced topics, resources)
   - Each module should have 2-6 steps

5. **Steps**:
   - Write in imperative mood ("Install dependencies", not "Installing dependencies")
   - Include either a command OR code example (or both if relevant)
   - For commands, use exact syntax (e.g., `npm install`, `python -m pip install`)
   - For code, include the language for syntax highlighting
   - Descriptions should explain WHY and WHAT, not just repeat the command

## Example Output

{
  "overview": "Next.js is a React framework for building full-stack web applications. It provides server-side rendering, static site generation, and built-in routing.",
  "prerequisites": [
    "Node.js 18.17 or higher",
    "Basic understanding of React and JSX",
    "Familiarity with JavaScript ES6+ syntax",
    "Text editor (VS Code recommended)"
  ],
  "structure": {
    "directories": [
      {"name": "app/", "description": "Main application code using App Router"},
      {"name": "public/", "description": "Static assets (images, fonts, etc.)"},
      {"name": "components/", "description": "Reusable React components"}
    ],
    "files": [
      {"name": "package.json", "description": "Project dependencies and scripts"},
      {"name": "next.config.js", "description": "Next.js configuration"},
      {"name": "tsconfig.json", "description": "TypeScript configuration"}
    ]
  },
  "modules": [
    {
      "id": "module-1",
      "title": "Environment Setup",
      "description": "Set up your development environment and create a new Next.js project",
      "stepIds": ["step-1", "step-2", "step-3"]
    },
    {
      "id": "module-2",
      "title": "Understanding App Router",
      "description": "Learn how Next.js App Router works and how to create pages",
      "stepIds": ["step-4", "step-5"]
    }
  ],
  "steps": [
    {
      "id": "step-1",
      "title": "Install Node.js",
      "description": "Next.js requires Node.js 18.17 or higher. Download and install from nodejs.org.",
      "command": "node --version"
    },
    {
      "id": "step-2",
      "title": "Create Next.js App",
      "description": "Use create-next-app to bootstrap a new project with TypeScript and App Router.",
      "command": "npx create-next-app@latest my-app --typescript --app"
    },
    {
      "id": "step-3",
      "title": "Start Development Server",
      "description": "Run the dev server to see your app at localhost:3000.",
      "command": "cd my-app && npm run dev"
    },
    {
      "id": "step-4",
      "title": "Create Your First Page",
      "description": "In App Router, pages are defined by page.tsx files inside the app directory.",
      "code": "export default function HomePage() {\n  return <h1>Welcome to Next.js!</h1>\n}",
      "language": "typescript"
    },
    {
      "id": "step-5",
      "title": "Add Dynamic Routes",
      "description": "Create dynamic routes using folder names with brackets, e.g., [id].",
      "code": "export default function PostPage({ params }: { params: { id: string } }) {\n  return <div>Post ID: {params.id}</div>\n}",
      "language": "typescript"
    }
  ]
}

## Now Generate

Based on the repository context provided below, generate a complete tutorial following the above guidelines and format.
```

åˆ›å»º Prompt æ„å»ºæœåŠ¡ `backend/app/services/prompt_builder.py`:

```python
from typing import List, Dict
from pathlib import Path
import structlog

logger = structlog.get_logger()

class PromptBuilder:
    """Prompt æ„å»ºæœåŠ¡"""

    MAX_CONTEXT_TOKENS = 4000  # ä¸ºä»£ç ä¸Šä¸‹æ–‡é¢„ç•™çš„ tokens

    def __init__(self):
        self.system_prompt = self._load_system_prompt()

    def _load_system_prompt(self) -> str:
        """åŠ è½½ç³»ç»Ÿ Prompt"""
        prompt_path = Path(__file__).parent.parent / "prompts" / "tutorial_generation.txt"
        return prompt_path.read_text(encoding="utf-8")

    def build_prompt(
        self,
        repo_info: dict,
        readme_content: str,
        code_chunks: List[Dict]
    ) -> List[Dict[str, str]]:
        """æ„å»ºå®Œæ•´ Prompt"""

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = self._build_user_message(
            repo_info, readme_content, code_chunks
        )

        return [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_message}
        ]

    def _build_user_message(
        self,
        repo_info: dict,
        readme_content: str,
        code_chunks: List[Dict]
    ) -> str:
        """æ„å»ºç”¨æˆ·æ¶ˆæ¯"""
        parts = []

        # 1. Repository Metadata
        parts.append("## Repository Metadata")
        parts.append(f"Name: {repo_info['owner']}/{repo_info['name']}")
        parts.append(f"Description: {repo_info.get('description', 'N/A')}")
        parts.append(f"Language: {repo_info.get('language', 'N/A')}")
        parts.append(f"Stars: {repo_info.get('stars', 0)}")
        parts.append("")

        # 2. README Content
        if readme_content:
            parts.append("## README Content")
            # æˆªå–å‰ 2000 å­—ç¬¦
            truncated_readme = readme_content[:2000]
            if len(readme_content) > 2000:
                truncated_readme += "\n... (truncated)"
            parts.append(truncated_readme)
            parts.append("")

        # 3. Relevant Code Snippets
        parts.append("## Relevant Code Snippets")
        parts.append("")

        for i, chunk in enumerate(code_chunks[:15], 1):  # æœ€å¤š 15 ä¸ªç‰‡æ®µ
            metadata = chunk["metadata"]
            parts.append(f"### Snippet {i}: {metadata['file_path']}")
            parts.append(f"Language: {metadata['language']}")
            parts.append(f"Lines: {metadata['start_line']}-{metadata['end_line']}")
            parts.append(f"```{metadata['language']}")
            parts.append(chunk["content"][:500])  # æ¯ä¸ªç‰‡æ®µæœ€å¤š 500 å­—ç¬¦
            parts.append("```")
            parts.append("")

        return "\n".join(parts)
```

---

### Task 4: å®ç° LLM è°ƒç”¨æœåŠ¡
**é¢„ä¼°**: 2 å°æ—¶

åˆ›å»º `backend/app/services/llm.py`:

```python
from typing import List, Dict, Optional
from openai import AsyncOpenAI
import structlog
import json
from app.core.config import settings

logger = structlog.get_logger()

class LLMService:
    """LLM è°ƒç”¨æœåŠ¡"""

    MODEL = "gpt-4-turbo-preview"
    TEMPERATURE = 0.3
    MAX_TOKENS = 4000
    MAX_RETRIES = 3

    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

    async def generate_tutorial(
        self,
        messages: List[Dict[str, str]]
    ) -> Dict:
        """ç”Ÿæˆæ•™ç¨‹"""
        for attempt in range(self.MAX_RETRIES):
            try:
                response = await self.client.chat.completions.create(
                    model=self.MODEL,
                    messages=messages,
                    temperature=self.TEMPERATURE,
                    max_tokens=self.MAX_TOKENS,
                    response_format={"type": "json_object"}
                )

                content = response.choices[0].message.content
                tutorial_data = json.loads(content)

                logger.info(
                    "tutorial_generated",
                    model=self.MODEL,
                    tokens_used=response.usage.total_tokens
                )

                return tutorial_data

            except json.JSONDecodeError as e:
                logger.error(
                    "llm_json_parse_error",
                    attempt=attempt + 1,
                    error=str(e),
                    content=content[:200]
                )

                if attempt == self.MAX_RETRIES - 1:
                    raise ValueError(f"Failed to parse LLM output as JSON: {e}")

            except Exception as e:
                logger.warning(
                    "llm_retry",
                    attempt=attempt + 1,
                    error=str(e)
                )

                if attempt == self.MAX_RETRIES - 1:
                    raise

                # æŒ‡æ•°é€€é¿
                import asyncio
                await asyncio.sleep(2 ** attempt)

        raise RuntimeError("Failed to generate tutorial after retries")

    def validate_tutorial_structure(self, data: dict) -> bool:
        """éªŒè¯æ•™ç¨‹ç»“æ„"""
        required_fields = [
            "overview", "prerequisites", "structure",
            "modules", "steps"
        ]

        for field in required_fields:
            if field not in data:
                logger.error("missing_required_field", field=field)
                return False

        # éªŒè¯ modules å’Œ steps å¼•ç”¨ä¸€è‡´æ€§
        step_ids = {step["id"] for step in data.get("steps", [])}
        for module in data.get("modules", []):
            for step_id in module.get("stepIds", []):
                if step_id not in step_ids:
                    logger.error(
                        "invalid_step_reference",
                        module=module["id"],
                        step_id=step_id
                    )
                    return False

        return True
```

**æµ‹è¯•**: åˆ›å»º `backend/tests/test_llm.py` (Mock OpenAI API)

---

### Task 5: å®ç°æ•™ç¨‹ç”Ÿæˆç¼–æ’æœåŠ¡
**é¢„ä¼°**: 2.5 å°æ—¶

åˆ›å»º `backend/app/services/tutorial_generation.py`:

```python
from typing import Dict, Optional
from pathlib import Path
import structlog
from app.services.vector_store import VectorStore
from app.services.prompt_builder import PromptBuilder
from app.services.llm import LLMService
from app.services.github_repo import GitHubRepoService
from app.schemas.tutorial import (
    TutorialData, TutorialGenerationStatus, RepoInfo
)

logger = structlog.get_logger()

class TutorialGenerationService:
    """æ•™ç¨‹ç”Ÿæˆç¼–æ’æœåŠ¡"""

    def __init__(self):
        self.vector_store = VectorStore()
        self.prompt_builder = PromptBuilder()
        self.llm = LLMService()
        self.github_service = GitHubRepoService()
        self.tasks: Dict[str, TutorialGenerationStatus] = {}
        self.cache: Dict[str, TutorialData] = {}  # ç®€å•å†…å­˜ç¼“å­˜

    async def generate_tutorial(
        self,
        task_id: str,
        repo_url: str,
        force: bool = False
    ) -> None:
        """ç”Ÿæˆæ•™ç¨‹ï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼‰"""
        try:
            # æ›´æ–°çŠ¶æ€
            self.tasks[task_id] = TutorialGenerationStatus(
                task_id=task_id,
                status="processing",
                progress={"stage": "initializing"}
            )

            # è§£æä»“åº“ URL
            owner, repo_name = self.github_service.parse_repo_url(repo_url)
            cache_key = f"{owner}:{repo_name}"

            # æ£€æŸ¥ç¼“å­˜
            if not force and cache_key in self.cache:
                logger.info("tutorial_cache_hit", repo=f"{owner}/{repo_name}")
                self.tasks[task_id] = TutorialGenerationStatus(
                    task_id=task_id,
                    status="completed",
                    tutorial=self.cache[cache_key]
                )
                return

            # 1. è·å–ä»“åº“ä¿¡æ¯
            logger.info("fetching_repo_info", repo=f"{owner}/{repo_name}")
            repo_info_raw = await self.github_service.get_repo_info(owner, repo_name)

            repo_info = RepoInfo(
                owner=owner,
                name=repo_name,
                description=repo_info_raw.get("description"),
                stars=repo_info_raw.get("stars", 0),
                language=repo_info_raw.get("language"),
                url=repo_url
            )

            self.tasks[task_id].progress = {"stage": "retrieving_context"}

            # 2. è·å– README
            readme_content = await self.vector_store.get_readme_content(
                owner, repo_name
            )

            # 3. å‘é‡æ£€ç´¢ç›¸å…³ä»£ç 
            logger.info("searching_relevant_code")
            query = f"How to use {repo_name}? Main features and examples."
            code_chunks = await self.vector_store.search_similar_chunks(
                owner, repo_name, query, top_k=20
            )

            if not code_chunks:
                raise ValueError(
                    f"No code chunks found for {owner}/{repo_name}. "
                    "Repository may not be vectorized."
                )

            self.tasks[task_id].progress = {"stage": "building_prompt"}

            # 4. æ„å»º Prompt
            logger.info("building_prompt")
            messages = self.prompt_builder.build_prompt(
                repo_info.dict(),
                readme_content or "",
                code_chunks
            )

            self.tasks[task_id].progress = {"stage": "generating_tutorial"}

            # 5. è°ƒç”¨ LLM
            logger.info("calling_llm")
            tutorial_raw = await self.llm.generate_tutorial(messages)

            # 6. éªŒè¯å’Œè§£æ
            logger.info("validating_output")
            if not self.llm.validate_tutorial_structure(tutorial_raw):
                raise ValueError("Generated tutorial has invalid structure")

            # 7. æ„å»ºå®Œæ•´ TutorialData
            tutorial_data = TutorialData(
                repo=repo_info,
                overview=tutorial_raw["overview"],
                prerequisites=tutorial_raw["prerequisites"],
                structure=tutorial_raw["structure"],
                modules=tutorial_raw["modules"],
                steps=tutorial_raw["steps"]
            )

            # 8. ç¼“å­˜ç»“æœ
            self.cache[cache_key] = tutorial_data

            # 9. æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            self.tasks[task_id] = TutorialGenerationStatus(
                task_id=task_id,
                status="completed",
                tutorial=tutorial_data
            )

            logger.info(
                "tutorial_generation_completed",
                task_id=task_id,
                repo=f"{owner}/{repo_name}",
                modules=len(tutorial_data.modules),
                steps=len(tutorial_data.steps)
            )

        except Exception as e:
            logger.error(
                "tutorial_generation_failed",
                task_id=task_id,
                error=str(e),
                exc_info=True
            )

            self.tasks[task_id] = TutorialGenerationStatus(
                task_id=task_id,
                status="failed",
                error=str(e)
            )

    def get_task_status(self, task_id: str) -> TutorialGenerationStatus:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return self.tasks.get(
            task_id,
            TutorialGenerationStatus(task_id=task_id, status="pending")
        )
```

**æµ‹è¯•**: åˆ›å»º `backend/tests/test_tutorial_generation.py`

---

### Task 6: åˆ›å»º API è·¯ç”±
**é¢„ä¼°**: 1 å°æ—¶

åˆ›å»º `backend/app/api/routes/tutorial.py`:

```python
from fastapi import APIRouter, BackgroundTasks, HTTPException, Query
from app.schemas.tutorial import (
    GenerateTutorialRequest,
    TutorialGenerationStatus
)
from app.services.tutorial_generation import TutorialGenerationService
import uuid

router = APIRouter(prefix="/api/tutorial", tags=["tutorial"])

tutorial_service = TutorialGenerationService()

@router.post("/generate", response_model=dict)
async def generate_tutorial(
    request: GenerateTutorialRequest,
    background_tasks: BackgroundTasks,
    force: bool = Query(False, description="Force regenerate")
):
    """ç”Ÿæˆæ•™ç¨‹"""
    try:
        task_id = str(uuid.uuid4())

        background_tasks.add_task(
            tutorial_service.generate_tutorial,
            task_id,
            request.repo_url,
            force or request.force
        )

        return {
            "ok": True,
            "data": {
                "task_id": task_id,
                "status": "processing"
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/{task_id}", response_model=dict)
async def get_tutorial_status(task_id: str):
    """è·å–æ•™ç¨‹ç”ŸæˆçŠ¶æ€"""
    status = tutorial_service.get_task_status(task_id)

    response = {
        "ok": True,
        "data": status.dict(exclude_none=True)
    }

    return response

# ä¾¿æ·ç«¯ç‚¹ï¼šç›´æ¥è·å–æ•™ç¨‹ï¼ˆé˜»å¡ï¼‰
@router.get("/by-url", response_model=dict)
async def get_tutorial_by_url(
    repo_url: str = Query(..., description="Repository URL"),
    force: bool = Query(False, description="Force regenerate")
):
    """ç›´æ¥è·å–æ•™ç¨‹ï¼ˆåŒæ­¥ï¼‰"""
    import uuid

    task_id = str(uuid.uuid4())

    # åŒæ­¥æ‰§è¡Œ
    await tutorial_service.generate_tutorial(task_id, repo_url, force)

    status = tutorial_service.get_task_status(task_id)

    if status.status == "failed":
        raise HTTPException(status_code=500, detail=status.error)

    return {
        "ok": True,
        "data": status.tutorial.dict() if status.tutorial else None
    }
```

åœ¨ `backend/app/api/router.py` ä¸­æ³¨å†Œè·¯ç”±ï¼š

```python
from app.api.routes import tutorial

api_router.include_router(tutorial.router)
```

---

### Task 7: åˆ›å»º Prompt ç›®å½•å’Œæ¨¡æ¿æ–‡ä»¶
**é¢„ä¼°**: 30 åˆ†é’Ÿ

```bash
mkdir -p backend/app/prompts
# å°† Task 3 ä¸­çš„ prompt å†…å®¹å†™å…¥ backend/app/prompts/tutorial_generation.txt
```

---

### Task 8: å•å…ƒæµ‹è¯•
**é¢„ä¼°**: 3 å°æ—¶

åˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼š
- `backend/tests/test_prompt_builder.py`: æµ‹è¯• Prompt æ„å»ºé€»è¾‘
- `backend/tests/test_llm.py`: Mock OpenAI API æµ‹è¯•
- `backend/tests/test_tutorial_generation.py`: é›†æˆæµ‹è¯•
- `backend/tests/test_vector_store_search.py`: æµ‹è¯•å‘é‡æ£€ç´¢

ç¤ºä¾‹æµ‹è¯• (`backend/tests/test_llm.py`):

```python
import pytest
from unittest.mock import AsyncMock, patch
from app.services.llm import LLMService

@pytest.mark.asyncio
async def test_generate_tutorial_success():
    """æµ‹è¯•æˆåŠŸç”Ÿæˆæ•™ç¨‹"""
    llm = LLMService()

    mock_response = {
        "overview": "Test overview" * 20,  # ç¡®ä¿é•¿åº¦è¶³å¤Ÿ
        "prerequisites": ["Node.js", "Git"],
        "structure": {"directories": [], "files": []},
        "modules": [
            {
                "id": "m1",
                "title": "Module 1",
                "description": "Desc",
                "stepIds": ["s1"]
            }
        ],
        "steps": [
            {
                "id": "s1",
                "title": "Step 1",
                "description": "Desc",
                "command": "npm install"
            }
        ]
    }

    with patch.object(llm.client.chat.completions, 'create', new_callable=AsyncMock) as mock_create:
        mock_create.return_value.choices[0].message.content = json.dumps(mock_response)
        mock_create.return_value.usage.total_tokens = 1500

        messages = [{"role": "user", "content": "Test"}]
        result = await llm.generate_tutorial(messages)

        assert result["overview"] == mock_response["overview"]
        assert len(result["modules"]) == 1
```

è¿è¡Œæµ‹è¯•:
```bash
cd backend
poetry run pytest tests/ -v --cov=app --cov-report=term-missing
```

---

### Task 9: é›†æˆæµ‹è¯•ï¼ˆç«¯åˆ°ç«¯ï¼‰
**é¢„ä¼°**: 1.5 å°æ—¶

åˆ›å»º `backend/tests/integration/test_tutorial_e2e.py`:

```python
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

@pytest.mark.asyncio
async def test_tutorial_generation_e2e():
    """ç«¯åˆ°ç«¯æµ‹è¯•ï¼šæ•™ç¨‹ç”Ÿæˆå®Œæ•´æµç¨‹"""

    # å‰æï¼šä»“åº“å·²å‘é‡åŒ–ï¼ˆå‡è®¾æµ‹è¯•ç¯å¢ƒå·²å‡†å¤‡ï¼‰

    # 1. å¯åŠ¨æ•™ç¨‹ç”Ÿæˆ
    response = client.post(
        "/api/tutorial/generate",
        json={"repo_url": "https://github.com/octocat/Hello-World"}
    )
    assert response.status_code == 200
    data = response.json()
    assert data["ok"] is True
    task_id = data["data"]["task_id"]

    # 2. è½®è¯¢çŠ¶æ€
    import time
    for _ in range(60):  # æœ€å¤šç­‰å¾… 60 ç§’
        response = client.get(f"/api/tutorial/{task_id}")
        status_data = response.json()["data"]
        status = status_data["status"]

        if status == "completed":
            break
        elif status == "failed":
            pytest.fail(f"Tutorial generation failed: {status_data.get('error')}")

        time.sleep(1)

    assert status == "completed"

    # 3. éªŒè¯æ•™ç¨‹æ•°æ®
    tutorial = status_data["tutorial"]
    assert tutorial["repo"]["owner"] == "octocat"
    assert tutorial["repo"]["name"] == "Hello-World"
    assert len(tutorial["overview"]) >= 200
    assert len(tutorial["prerequisites"]) >= 2
    assert len(tutorial["modules"]) >= 3
    assert len(tutorial["steps"]) >= 5

    # 4. éªŒè¯ modules å’Œ steps å¼•ç”¨ä¸€è‡´
    step_ids = {s["id"] for s in tutorial["steps"]}
    for module in tutorial["modules"]:
        for step_id in module["stepIds"]:
            assert step_id in step_ids
```

---

### Task 10: æ–‡æ¡£æ›´æ–°
**é¢„ä¼°**: 30 åˆ†é’Ÿ

æ›´æ–° `backend/README.md`:

```markdown
## æ•™ç¨‹ç”ŸæˆæœåŠ¡

### ç”Ÿæˆæ•™ç¨‹ï¼ˆå¼‚æ­¥ï¼‰

**POST** `/api/tutorial/generate`

Request:
\`\`\`json
{
  "repo_url": "https://github.com/facebook/react",
  "force": false
}
\`\`\`

Response:
\`\`\`json
{
  "ok": true,
  "data": {
    "task_id": "uuid...",
    "status": "processing"
  }
}
\`\`\`

### æŸ¥è¯¢ç”ŸæˆçŠ¶æ€

**GET** `/api/tutorial/{task_id}`

Response:
\`\`\`json
{
  "ok": true,
  "data": {
    "task_id": "...",
    "status": "completed",
    "tutorial": { /* TutorialData */ }
  }
}
\`\`\`

### ç›´æ¥è·å–æ•™ç¨‹ï¼ˆåŒæ­¥ï¼‰

**GET** `/api/tutorial/by-url?repo_url=https://github.com/...`

Response:
\`\`\`json
{
  "ok": true,
  "data": { /* TutorialData */ }
}
\`\`\`
```

---

### Task 11: æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜
**é¢„ä¼°**: 1 å°æ—¶

åœ¨ `TutorialGenerationService` ä¸­ä¼˜åŒ–ç¼“å­˜æœºåˆ¶ï¼ˆè€ƒè™‘ä½¿ç”¨ Redisï¼‰ï¼š

```python
# å¯é€‰ï¼šä½¿ç”¨ Redis ä½œä¸ºç¼“å­˜
import redis.asyncio as redis

class TutorialGenerationService:
    def __init__(self):
        # ...
        self.redis = redis.from_url("redis://localhost:6379")

    async def _get_from_cache(self, cache_key: str) -> Optional[TutorialData]:
        """ä» Redis è·å–ç¼“å­˜"""
        cached = await self.redis.get(f"tutorial:{cache_key}")
        if cached:
            return TutorialData.parse_raw(cached)
        return None

    async def _set_cache(self, cache_key: str, tutorial: TutorialData):
        """è®¾ç½® Redis ç¼“å­˜ï¼ˆ24 å°æ—¶ï¼‰"""
        await self.redis.setex(
            f"tutorial:{cache_key}",
            86400,  # 24 hours
            tutorial.json()
        )
```

---

### Task 12: Prompt ç‰ˆæœ¬æ§åˆ¶å’Œ A/B æµ‹è¯•æ”¯æŒ
**é¢„ä¼°**: 1 å°æ—¶

åˆ›å»º `backend/app/prompts/` ç›®å½•ç»“æ„ï¼š

```
backend/app/prompts/
â”œâ”€â”€ tutorial_generation_v1.txt
â”œâ”€â”€ tutorial_generation_v2.txt  # å®éªŒç‰ˆæœ¬
â””â”€â”€ active_version.txt          # å½“å‰ä½¿ç”¨çš„ç‰ˆæœ¬å·
```

åœ¨ `PromptBuilder` ä¸­æ”¯æŒç‰ˆæœ¬é€‰æ‹©ï¼š

```python
class PromptBuilder:
    def __init__(self, version: str = "v1"):
        self.version = version
        self.system_prompt = self._load_system_prompt()

    def _load_system_prompt(self) -> str:
        prompt_path = (
            Path(__file__).parent.parent
            / "prompts"
            / f"tutorial_generation_{self.version}.txt"
        )
        return prompt_path.read_text(encoding="utf-8")
```

---

## ğŸš¨ é£é™©ä¸ä¾èµ–

### é£é™©è¯„ä¼°

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|----------|
| LLM è¾“å‡ºæ ¼å¼ä¸ç¨³å®š | é«˜ | é«˜ | ä½¿ç”¨ JSON Modeã€ä¸¥æ ¼ Promptã€è¾“å‡ºéªŒè¯ |
| OpenAI API è´¹ç”¨é«˜ | ä¸­ | é«˜ | ç¼“å­˜æœºåˆ¶ã€é™åˆ¶å¹¶å‘ã€ç›‘æ§ä½¿ç”¨é‡ |
| ç”Ÿæˆè´¨é‡ä¸ä½³ | ä¸­ | é«˜ | Prompt è¿­ä»£ä¼˜åŒ–ã€Few-shot Examplesã€äººå·¥å®¡æ ¸ |
| å‘é‡æ£€ç´¢ç»“æœä¸ç›¸å…³ | ä¸­ | ä¸­ | ä¼˜åŒ–æ£€ç´¢ç­–ç•¥ã€è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼ |
| è¶…æ—¶é—®é¢˜ | ä¸­ | ä¸­ | å¼‚æ­¥å¤„ç†ã€åˆç†çš„è¶…æ—¶è®¾ç½® |

### ä¾èµ–å…³ç³»

**å‰ç½®ä¾èµ–**:
- STORY-2.2: å†…å®¹å¤„ç†ä¸å‘é‡åŒ–æœåŠ¡ï¼ˆéœ€è¦å‘é‡æ•°æ®ï¼‰

**åç»­ä¾èµ–**:
- STORY-1.2: å‰ç«¯åŸºç¡€åº”ç”¨ï¼ˆéœ€è¦æ›¿æ¢ Mock APIï¼‰
- STORY-2.4: å­¦ä¹ è·¯å¾„ç”Ÿæˆï¼ˆå¯èƒ½å¤ç”¨éƒ¨åˆ†é€»è¾‘ï¼‰

---

## âœ… Definition of Done

- [ ] æ‰€æœ‰ 12 ä¸ªéªŒæ”¶æ ‡å‡†é€šè¿‡
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥ 80%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡ï¼ˆç«¯åˆ°ç«¯æ•™ç¨‹ç”Ÿæˆï¼‰
- [ ] API æ–‡æ¡£æ›´æ–°
- [ ] Prompt æ¨¡æ¿æ–‡æ¡£åŒ–
- [ ] ä»£ç ç¬¦åˆ `coding-standards.md` è§„èŒƒ
- [ ] Code Review é€šè¿‡
- [ ] æˆåŠŸä¸ºæµ‹è¯•ä»“åº“ç”Ÿæˆæ•™ç¨‹ï¼ˆè´¨é‡äººå·¥éªŒè¯ï¼‰
- [ ] LLM è¾“å‡ºéªŒè¯é€»è¾‘å®Œå–„
- [ ] ç¼“å­˜æœºåˆ¶å·¥ä½œæ­£å¸¸
- [ ] é”™è¯¯å¤„ç†å®Œå–„ï¼ˆAPI é”™è¯¯ã€æ ¼å¼é”™è¯¯ç­‰ï¼‰
- [ ] æ€§èƒ½æµ‹è¯•ï¼šç”Ÿæˆå•ä¸ªæ•™ç¨‹ â‰¤ 60 ç§’
- [ ] æ—¥å¿—è®°å½•å®Œå–„

---

## ğŸ“ Dev Agent Record

### å¼€å‘æ—¥å¿—

**æ—¶é—´**: YYYY-MM-DD
**å¼€å‘è€…**: Dev Agent

#### è¿›å±•
- [ ] Task 1: æ•°æ®æ¨¡å‹è®¾è®¡
- [ ] Task 2: å‘é‡æ£€ç´¢æœåŠ¡
- [ ] Task 3: Prompt æ¨¡æ¿
- [ ] Task 4: LLM è°ƒç”¨æœåŠ¡
- [ ] Task 5: æ•™ç¨‹ç”Ÿæˆç¼–æ’
- [ ] Task 6: API è·¯ç”±
- [ ] Task 7-12: Prompt æ–‡ä»¶ã€æµ‹è¯•ã€æ–‡æ¡£ã€ä¼˜åŒ–

#### æŠ€æœ¯å†³ç­–
- LLM æ¨¡å‹é€‰æ‹©: gpt-4-turbo-previewï¼ˆå¹³è¡¡è´¨é‡å’Œæˆæœ¬ï¼‰
- JSON Mode: å¼ºåˆ¶ç»“æ„åŒ–è¾“å‡º
- ç¼“å­˜ç­–ç•¥: å†…å­˜ç¼“å­˜ï¼ˆMVPï¼‰+ Redisï¼ˆå¯é€‰ï¼‰
- Prompt è®¾è®¡: System + Few-shot + åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥

#### Prompt è¿­ä»£è®°å½•
- v1: åˆå§‹ç‰ˆæœ¬ï¼ˆTask 3 ä¸­çš„æ¨¡æ¿ï¼‰
- v2: (å¾…ä¼˜åŒ–) å¢åŠ æ›´å¤š Few-shot Examplesï¼Œä¼˜åŒ–æŒ‡ä»¤æ¸…æ™°åº¦

#### é‡åˆ°çš„é—®é¢˜
_(è®°å½•å®é™…å¼€å‘ä¸­é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ)_

#### æµ‹è¯•ç»“æœ
_(è®°å½•æµ‹è¯•è¦†ç›–ç‡å’Œç”Ÿæˆè´¨é‡è¯„ä¼°)_

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [Epic: MVP v0.1](./epic-mvp-v0.1.md)
- [Story 2.2: å†…å®¹å‘é‡åŒ–](./story-2.2-content-vectorization.md)
- [Story 1.2: å‰ç«¯åŸºç¡€åº”ç”¨](./story-1.2-frontend-foundation.md)
- [æ¶æ„æ–‡æ¡£](../architecture.md)
- [UX è§„æ ¼](../ux/ux-spec.md)
- [æŠ€æœ¯æ ˆ](../architecture/tech-stack.md)
- [ç¼–ç è§„èŒƒ](../architecture/coding-standards.md)
- [OpenAI Chat API](https://platform.openai.com/docs/guides/chat)
- [OpenAI JSON Mode](https://platform.openai.com/docs/guides/text-generation/json-mode)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
